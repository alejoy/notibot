import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time
import re
import os
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Telegram Config - usar variables de entorno
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')

# Validar que existan las variables
if not TELEGRAM_BOT_TOKEN:
    logger.error("‚ùå Falta TELEGRAM_BOT_TOKEN en variables de entorno")
    exit(1)

if not OPENROUTER_API_KEY:
    logger.error("‚ùå Falta OPENROUTER_API_KEY en variables de entorno")
    exit(1)

logger.info("‚úÖ Variables de entorno cargadas correctamente")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"
}

# Configuraci√≥n de sitios
SITIOS = [
    {
        "nombre": "R√≠o Negro",
        "url": "https://www.rionegro.com.ar/politica/",
        "content_selector": {
            "tag": "div",
            "class_": "newsfull__body"
        },
        "link_pattern": "/politica/"
    },
    {
        "nombre": "P√°gina/12",
        "url": "https://www.pagina12.com.ar/secciones/el-pais",
        "content_selector": {
            "tag": "div",
            "class_": "article-main-content"
        },
        "link_pattern_regex": r"^\/\d{6,}-.+"
    },
    {
        "nombre": "La Naci√≥n",
        "url": "https://www.lanacion.com.ar/politica/",
        "content_selector": {
            "tag": "div",
            "class_": "com-paragraph"
        },
        "link_pattern": "/politica/"
    },
    {
        "nombre": "Infobae",
        "url": "https://www.infobae.com/politica/",
        "content_selector": {
            "tag": "figcaption",
            "class_": "article-figcaption-img"
        },
        "link_pattern": "/politica/"
    }
]

# Configuraci√≥n de tonos
TONOS = {
    "libertario": "Analiz√° esta noticia desde una perspectiva libertaria, enfoc√°ndote en la libertad individual, el libre mercado y la limitaci√≥n del Estado.",
    "cr√≠tico al neoliberalismo": "Analiz√° esta noticia con una perspectiva cr√≠tica al neoliberalismo, enfoc√°ndote en desigualdades sociales y el rol del Estado en la protecci√≥n social.",
    "neutral informativo": "Resum√≠ esta noticia de forma objetiva y neutral, presentando los hechos principales sin sesgo pol√≠tico."
}

TONOS_POSIBLES = ["libertario", "cr√≠tico al neoliberalismo", "neutral informativo"]

def obtener_chat_ids():
    SUPABASE_URL = os.getenv("SUPABASE_URL")
    SUPABASE_KEY = os.getenv("SUPABASE_KEY")

    try:
        response = requests.get(
            f"{SUPABASE_URL}/rest/v1/subscribers?select=chat_id,nombre",
            headers={
                "apikey": SUPABASE_KEY,
                "Authorization": f"Bearer {SUPABASE_KEY}"
            }
        )
        if response.status_code == 200:
            datos = response.json()
            return [(item["chat_id"], item.get("nombre", "")) for item in datos]
        else:
            print(f"‚ùå Error al obtener chat_ids: {response.text}")
            return []
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return []

def enviar_telegram(mensaje, chat_id):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    data = {
        "chat_id": chat_id,
        "text": mensaje,
        "parse_mode": "Markdown"
    }
    try:
        response = requests.post(url, data=data)
        if response.status_code == 200:
            print(f"‚úÖ Mensaje enviado a {chat_id}")
            return True
        else:
            print(f"‚ùå Error enviando mensaje: {response.text}")
            return False
    except Exception as e:
        print(f"‚ùå Excepci√≥n al enviar mensaje por Telegram: {e}")
        return False

def obtener_enlaces(sitio):
    url = sitio["url"]
    nombre = sitio["nombre"]
    print(f"üì• Obteniendo enlaces de {nombre}...")
    
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, "html.parser")
        enlaces = set()

        for link in soup.find_all("a", href=True):
            href = link["href"]
            is_article = False
            
            if "link_pattern_regex" in sitio:
                pattern_regex = sitio["link_pattern_regex"]
                if re.match(pattern_regex, href):
                    is_article = True
            elif "link_pattern" in sitio:
                pattern = sitio["link_pattern"]
                if pattern in href:
                    is_article = True

            if is_article:
                full_url = urljoin(url, href)
                enlaces.add(full_url)

        print(f"‚úÖ Encontrados {len(enlaces)} enlaces √∫nicos para {nombre}.")
        return list(enlaces)[:3]

    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error al conectar con {url}: {e}")
        return []

def extraer_contenido(url, selector):
    print(f"   üìÑ Extrayendo contenido de: {url[:70]}...")
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        find_args = {}
        if 'class_' in selector:
            find_args['class_'] = selector['class_']
        if 'attrs' in selector:
            find_args['attrs'] = selector['attrs']

        contenedor = soup.find(selector['tag'], **find_args)

        if not contenedor:
            print(f"   ‚ö†Ô∏è No se encontr√≥ el contenedor principal. Intentando alternativas...")
            fallback_selectors = [
                {'tag': 'div', 'class_': 'content'},
                {'tag': 'div', 'class_': 'article-body'},
                {'tag': 'div', 'class_': 'post-content'},
                {'tag': 'article'},
                {'tag': 'main'}
            ]
            for fallback in fallback_selectors:
                fb_args = {}
                if 'class_' in fallback:
                    fb_args['class_'] = fallback['class_']
                contenedor = soup.find(fallback['tag'], **fb_args)
                if contenedor:
                    print(f"   ‚úÖ Usando selector alternativo: {fallback}")
                    break
            if not contenedor:
                print(f"   ‚ùå No se pudo encontrar contenido con ning√∫n selector")
                return None

        for script in contenedor(["script", "style", "nav", "footer", "header"]):
            script.decompose()

        texto = ' '.join(contenedor.get_text(separator=' ', strip=True).split())
        if len(texto) < 100:
            print(f"   ‚ö†Ô∏è Contenido muy corto ({len(texto)} caracteres)")
            return None

        return texto

    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error al extraer contenido de {url}: {e}")
        return None

def resumir_con_tono(texto, tono):
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }

    prompt = TONOS.get(tono, "Resum√≠ el siguiente texto de forma clara y breve.") + f"\n\n{texto[:4000]}"

    data = {
        "model": "mistralai/mixtral-8x7b-instruct",
        "messages": [
            {"role": "system", "content": f"Sos un analista pol√≠tico con enfoque {tono}."},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 300
    }

    for intento in range(3):
        try:
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=40
            )
            if response.status_code == 200:
                return response.json()['choices'][0]['message']['content'].strip()
            else:
                print(f"‚ö†Ô∏è Intento {intento+1} fallido: {response.status_code} - {response.text}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error en intento {intento+1}: {e}")
        time.sleep(2)

    return "[No se pudo generar resumen]"

def ejecutar_bot():
    print("ü§ñ Iniciando bot de noticias...")

    chat_ids = obtener_chat_ids()
    if not chat_ids:
        print("‚ö†Ô∏è No hay suscriptores registrados.")
        return

    for sitio in SITIOS:
        print(f"\nüåê Procesando sitio: {sitio['nombre']}")
        enlaces = obtener_enlaces(sitio)

        if not enlaces:
            print(f"No se pudieron obtener enlaces para {sitio['nombre']}. Saltando al siguiente.\n")
            continue

        for link in enlaces:
            print(f"üîó Procesando: {link}")
            contenido = extraer_contenido(link, sitio['content_selector'])

            if contenido:
                resumenes = []
                for tono in TONOS_POSIBLES:
                    print(f"   üé≠ Generando resumen con tono: {tono}")
                    resumen = resumir_con_tono(contenido, tono)
                    resumenes.append(f"üó£ *{tono.capitalize()}*\n{resumen}")

                mensaje = f"üì∞ *{sitio['nombre']} - Comparativa de enfoques*\n\n" + \
                          "\n\n".join(resumenes) + \
                          f"\n\nüîó {link}"

                for chat_id in chat_ids:
                    enviar_telegram(mensaje, chat_id)
                time.sleep(5)
            else:
                print("‚ö†Ô∏è No se pudo extraer contenido del art√≠culo.")

    print("\nüèÅ Bot finalizado.")

if __name__ == "__main__":
    ejecutar_bot()
